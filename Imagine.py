# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11nZKWNYT8NlUbzsAQHzFTjOgDBNU5kvY
"""

!git clone https://github.com/huggingface/diffusers.git

!git clone https://github.com/google/dreambooth.git

# Commented out IPython magic to ensure Python compatibility.
# %cd diffusers

!pip install -e .

# Commented out IPython magic to ensure Python compatibility.
# %cd examples/dreambooth

!pip install -r requirements.txt

!pip install diffusers transformers

!pip install xformers

!pip install bitsandbytes

!pip install --upgrade diffusers huggingface_hub
from huggingface_hub.constants import HF_HOME

!pip install --upgrade huggingface_hub

!accelerate config default

from huggingface_hub import snapshot_download

local_dir = "./dog"
snapshot_download(
    "diffusers/dog-example",
    local_dir=local_dir, repo_type="dataset",
    ignore_patterns=".gitattributes",
)

!rm -rf /content/diffusers/examples/dreambooth/dog/.cache
!rm -rf /content/diffusers/examples/dreambooth/dog/.ipynb_checkpoints

import torch

torch.cuda.set_per_process_memory_fraction(0.5, 0)

!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

torch.cuda.empty_cache()

!huggingface-cli login

!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64

!export MODEL_NAME="CompVis/stable-diffusion-v1-4"
!export INSTANCE_DIR="dog"
!export CLASS_DIR="path-to-class-images"
!export OUTPUT_DIR="path-to-save-model"

!accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path="CompVis/stable-diffusion-v1-4"  \
  --instance_data_dir="/content/diffusers/examples/dreambooth/dog" \
  --class_data_dir="/content/diffusers/examples/dreambooth/dog" \
  --output_dir="/content/models/dreambooth_output" \
  --with_prior_preservation --prior_loss_weight=1.0 \
  --instance_prompt="my dog teddy" \
  --class_prompt="a photo of dog" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 --gradient_checkpointing \
  --use_8bit_adam \
  --enable_xformers_memory_efficient_attention \
  --set_grads_to_none \
  --learning_rate=2e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --num_class_images=5 \
  --max_train_steps=800 \
  --push_to_hub

!pip install diffusers

!pip install transformers

!ls

from diffusers import StableDiffusionPipeline
import torch
from IPython.display import display

model_id = "/content/models/dreambooth_output"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to("cuda")

prompt = "dog in in beach"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("/content/dogbeach.png")
display(image)

prompt = "dog in in living room"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("/content/dogROOM.png")
display(image)

prompt = "my dog teddy in park"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("/content/dogbeach.png")
display(image)

prompt = "my dog teddy in beach"
image = pipe(prompt, num_inference_steps=100, guidance_scale=7.5).images[0]

image.save("/content/dogbeach.png")
display(image)

prompt = "my dog teddy playing in beach"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("/content/dogplaybeach.png")
display(image)

prompt = "my dog teddy in lawn"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("/content/doglawn.png")
display(image)

prompt = "my dog teddy in snow"
image = pipe(prompt, num_inference_steps=100, guidance_scale=7.5).images[0]

image.save("/content/dogmount.png")
display(image)

prompt = "tiger in beach"
image = pipe(prompt, num_inference_steps=100, guidance_scale=7.5).images[0]

image.save("/content/tiger.png")
display(image)

